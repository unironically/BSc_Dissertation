\documentclass[a4paper, 11pt]{article}
\usepackage{graphbox}
\usepackage{fancyhdr}
\usepackage{caption}
\usepackage{fancyvrb}
\usepackage{float}

\fancypagestyle{title}{
\renewcommand{\headrulewidth}{0pt}
\fancyhf{}
\lhead{Luke Bessant - 2019}
\rhead{}
}
\pagestyle{title}

\title{\textbf{CS3821 Full Unit Project}\\Technical Report on Proof of Concept Programs}
\author{Luke Bessant\\Supervisor: Reuben Rowe}
\date{\today}

\begin{document}

\maketitle
\thispagestyle{title}
\newpage

\tableofcontents
\clearpage
\newpage

\section{Introduction}

\clearpage
\section{BNF Pretty Printer}
The first proof of concept program written was one which is able to take in a grammar written in extended-BNF format from a file and pretty print it. Meaning the grammar is outputt back to the user in a structure which is much easier to read. This program was first proposed with the idea that it would allow me to gain experience in using abstract syntax trees. Whilst this was the case, I would also say that a large portion of the benefit of working on this program was learning how to write a context-free grammar.
\\\newline
The ANTLR parser generator was used in the making of this program, with which we could write a grammar which recognises other EBNF grammars. This grammar supports grouping of production clauses, optional clauses, kleene and positive closures, as well as empty productions. Upon the passing of a file containing the EBNF grammar to the program, the ANTLR parser generator is used to generate an abstract syntax tree containing the structure of the productions within the file. We can then recursively handle each sub-tree, corresponding to a single production rule, whose contents we can properly format by trimming whitespace and creating a new line for alternations.

\begin{figure}[H]
\centering
\begin{BVerbatim}
start ::= '[' digit_list ']' .
digit_list ::= digit digit_tail . 
digit_tail ::= # 
	| ',' digit_list . 
digit ::= '0' 
	| '1' 
	| ( '2' | 'two' ) 
	| '3' 
	| '4' .
\end{BVerbatim}
\caption{Example pretty printed grammar output}
\end{figure}

\noindent No meaningful problems were encountered during the building of this program, the only research being into how the syntax trees generated by ANTLR are formatted. Test-driven development with JUnit test suites was used to ensure that the program could be built without any bugs which could otherwise have been introduced.

\clearpage
\section{Stack Code Interpreter}
The purpose of this program was to make a simple four function calculator, demonstrating the ability to use abstract syntax trees and the understanding of interpretation. As well as this, the program was written in such a way that we also perform some simple code generation. Namely, the expression the user inputs is converted to a stack code format (shown below) which is then interpreted by the program to produce the desired result. This program uses the type Double for both inputs and outputs, allowing for necessary precision.

\begin{figure}[H]
\centering
\begin{BVerbatim}
PUSH 10.0;
PUSH 5.0;
ADD;
PUSH 2.0;
DIV;
PUSH 2.5;
MUL;
\end{BVerbatim}
\caption{Example stack code for expression (10+5)/2*2.5}
\end{figure}

\noindent A grammar was written which supports infix expressons using addition, subtraction, multiplication and addition, for which a parser was generated using ANTLR. I then implemented a class with which we reduce the syntax tree to the format shown below to make it easier to convert to stack code. This reduced tree is then traversed with a post-order search, allowing us to push the left and right sub-expressions of an operation it itself is performed, as shown above where we push \texttt{10.0} and \texttt{5.0} before adding them. A grammar was then written which recognises this stack code, so that we can interpret it and calculate the result of the original expression. 

\begin{figure}[ht!]
	\centering
	\includegraphics[width=30mm]{/home/luke/Pictures/syntax_tree4.png}
	{\caption{Example reduced syntax tree for 10+5}}
\end{figure}

\noindent JUnit testing was used in the making of this program to reduce the likelihood of bugs being introduced. There were no major learning curves to note, where, as before, the only research necessary was into the formatting of trees generated by ANTLR which we then have to traverse. 

\clearpage
\section{Lexer Generator}
The third proof of concept program involved writing a program that could recognise and write the automata necessary to support user inputs given some regular expression. Thus the idea was to write something that could, given some extension, assign user inputs a token based on a set of regular expressions. Currently the program takes one regular expression as an argument when it is run, builds the automata which recognise it and then poll the user for strings, outputting for each whether the automaton reaches an accepting state at the end of the string.
\\\newline 
The aim is to generate the most minimal deterministic finite-state automaton with the least number of states possible, as this will be the most efficient tool with which to accept or reject a string. To do this, the input regular expression is first expanded into a format which Thompson's construction can understand, e.g. \texttt{[a-b][a-bA-B0-1]*} is converted to \texttt{(a|b)(a|b|A|B|0|1)*}. We then perform Thompson's construction with this expression. However for large expressions Thompson's construction gives us a large number of states, much more than is necessary, which will slow down the generation of a deterministic finite-state automata when using powerset construction, an $O(2^n)$ algorithm where $n$ is the number of states the input nondeterministic finite-state automata has.
\\\newline
With this in mind when performing Thompson's construction, we minimise the automaton generated by each recursive step of the construction before returning it. For instance with the regular expression \texttt{(a|(b|c))*}, we first create the NFA for \texttt{(b|c)}, then perform the powerset construction to generate the DFA for this, then hopcroft's algorithm to convert this to the minimal DFA. We then do the same for \texttt{(a|(b|c)}, and for \texttt{(a|(b|c))*}. We then run the final NFA from this construction through the powerset construction and Hopcroft's algorithm to get the final minimal DFA for the regular expression. For example, the most minimal DFA the program can generate for the expression \texttt{[a-z][a-zA-Z0-9]*} consists of two states: the start state (0) from which we transition to the final state (1) with any lower case letter, and the final state can transition to itself on any lower or upper case letter, or any integer (e.g. \textit{varCat1911}).
\\\newline
As with the other programs, this one was developed using TDD with JUnit. The significant hurdle when writing this program was fixing the exponentially long running time of the powerset construction. At first, the generation of the DFA for the regular expression noted in the last example took at least a minute. In order to fix this, the minimal DFA was generated for each recursive step of Thompson's construction as previously explained.

\end{document}
